name: Build and test

on:
  workflow_call:
    inputs:
      version:
        description: Version to be assigned to the built image
        required: true
        type: string
      branch:
        default: ci
        description: Branch that given job relates to, that value will be used to tag docker image mangatasolutions/mangata-node:<BRANCH_NAME>
        required: true
        type: string
      builder_image:
        default: mangatasolutions/node-builder:multi-nightly-2023-05-22
        description: Docker image used for Rust builds
        required: false
        type: string
      cache-version:
        default: 2
        description: Cache version variable to be used to invalidate cache when needed
        required: false
        type: number
      cache-enabled:
        default: true
        description: Enable cargo build cache
        required: false
        type: boolean

permissions:
  contents: read
  id-token: write

env:
  NODE_DOCKER_IMAGE_REPOSITORY: mangatasolutions/rollup-node

jobs:
  # Reference implementation source: https://docs.docker.com/build/ci/github-actions/multi-platform/#distribute-build-across-multiple-runners
  build-node-image:
    name: Build Docker image
    strategy:
      matrix:
        platform:
          - name: amd64
            runner: compile-gke
          - name: arm64
            runner: compile-gke-arm
    runs-on: ${{ matrix.platform.runner }}
    env:
      JOB_CACHE_PREFIX: docker-buildx-cache-${{ matrix.platform.name }}-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
    
      - name: Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}
      - uses: docker/setup-buildx-action@v3
      - run: curl -LJO https://github.com/reproducible-containers/buildkit-cache-dance/archive/refs/tags/v3.1.2.tar.gz && tar xvf buildkit-cache-dance-3.1.2.tar.gz
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }}

      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false
      
          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - ; then
            echo "Injecting buildkit mount cache into Docker system"
            node ./buildkit-cache-dance-3.1.2/dist/index.js --cache-map '{"usr-local-cargo-registry": "/usr/local/cargo/registry", "usr-local-cargo-git": "/usr/local/cargo/git", "app-target": "/app/target"}'
            
            CACHE_FOUND=true
          fi
      
          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT
      
      - name: Build and push by digest
        id: build
        uses: docker/build-push-action@v6
        with:
          platforms: linux/${{ matrix.platform.name }}
          labels: ${{ steps.meta.outputs.labels }}
          outputs: type=image,name=${{ env.NODE_DOCKER_IMAGE_REPOSITORY }},push-by-digest=true,name-canonical=true,push=true
      
      - name: Export digest
        run: |
          mkdir -p /tmp/digests
          digest="${{ steps.build.outputs.digest }}"
          touch "/tmp/digests/${digest#sha256:}"
      
      - name: Upload digest
        uses: actions/upload-artifact@v4
        with:
          name: digests-linux-${{ matrix.platform.name }}
          path: /tmp/digests/*
          if-no-files-found: error
          retention-days: 1
      
      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
        
          echo "Extracting buildkit cache from Docker system"
          node ./buildkit-cache-dance-3.1.2/dist/index.js --extract --cache-map '{"usr-local-cargo-registry": "/usr/local/cargo/registry", "usr-local-cargo-git": "/usr/local/cargo/git", "app-target": "/app/target"}'
          
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "usr-local-cargo-registry"
            "usr-local-cargo-git"
            "app-target"
          )
      
            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"
      
            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"
  
  build-node-image-with-fast-runtime:
    name: Build fast runtime Docker image (AMD64 platform only)
    runs-on: compile-gke
    env:
      JOB_CACHE_PREFIX: docker-buildx-cache-fast-runtime-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4

      - name: Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}
          tags: |
            type=raw,value=${{ inputs.version }}-fast
            type=raw,value=${{ inputs.branch }}-fast

      - uses: docker/setup-buildx-action@v3
      - run: curl -LJO https://github.com/reproducible-containers/buildkit-cache-dance/archive/refs/tags/v3.1.2.tar.gz && tar xvf buildkit-cache-dance-3.1.2.tar.gz
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }}

      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2
      
      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false
  
          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - ; then
            echo "Injecting buildkit mount cache into Docker system"
            node ./buildkit-cache-dance-3.1.2/dist/index.js --cache-map '{"usr-local-cargo-registry": "/usr/local/cargo/registry", "usr-local-cargo-git": "/usr/local/cargo/git", "app-target": "/app/target"}'
            
            CACHE_FOUND=true
          fi
  
          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT
      
      - name: Build and push fast runtime image
        uses: docker/build-push-action@v6
        with:
          build-args: "ENABLE_FAST_RUNTIME=true"
          platforms: linux/amd64
          labels: ${{ steps.meta.outputs.labels }}
          tags: ${{ steps.meta.outputs.tags }}
          push: true
  
      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
        
          echo "Extracting buildkit cache from Docker system"
          node ./buildkit-cache-dance-3.1.2/dist/index.js --extract --cache-map '{"usr-local-cargo-registry": "/usr/local/cargo/registry", "usr-local-cargo-git": "/usr/local/cargo/git", "app-target": "/app/target"}'
          
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "usr-local-cargo-registry"
            "usr-local-cargo-git"
            "app-target"
          )
  
            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"
  
            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"
  
  create-docker-image-manifest-and-export-wasms:
    name: Generate multiplatform Docker image manifest
    needs: [build-node-image,build-node-image-with-fast-runtime]
    runs-on: ubuntu-latest
    steps:
      - name: Download digests
        uses: actions/download-artifact@v4
        with:
          path: /tmp/digests
          pattern: digests-*
          merge-multiple: true
      
      - uses: docker/setup-buildx-action@v3
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKERHUB_TOKEN }}
      
      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}
          tags: |
            type=raw,value=${{ inputs.version }}
            type=raw,value=${{ inputs.branch }}
      
      - name: Create manifest list and push
        working-directory: /tmp/digests
        run: |
          docker buildx imagetools create $(jq -cr '.tags | map("-t " + .) | join(" ")' <<< "$DOCKER_METADATA_OUTPUT_JSON") \
            $(printf '${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}@sha256:%s ' *)          
      
      - name: Inspect image
        run: docker buildx imagetools inspect ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}:${{ steps.meta.outputs.version }}

      - name: Export WASM artifacts from built images
        run: |
          # Export WASM artifact from image with regular runtime
          container_id=$(docker create ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}:${{ inputs.version }}) && \
            docker cp $container_id:/app/rollup_runtime.compact.compressed.wasm ./rollup_runtime-${{ inputs.version }}.compact.compressed.wasm && \
            docker rm $container_id
          
          # Export WASM artifact from image with fast runtime
          container_id_fast=$(docker create ${{ env.NODE_DOCKER_IMAGE_REPOSITORY }}:${{ inputs.version }}-fast) && \
            docker cp $container_id_fast:/app/rollup_runtime.compact.compressed.wasm ./rollup_runtime-${{ inputs.version }}-fast.compact.compressed.wasm && \
            docker rm $container_id_fast
      
      - uses: actions/upload-artifact@v3
        with:
          name: wasms-${{ inputs.version }}
          path: |
            ./rollup_runtime-${{ inputs.version }}.compact.compressed.wasm
            ./rollup_runtime-${{ inputs.version }}-fast.compact.compressed.wasm

  rustfmt-check:
    name: Formatting check
    runs-on: ubuntu-latest
    container:
      image: ${{ inputs.builder_image }}
    steps:
      - uses: actions/checkout@v4
      - name: Check formatting
        run: cargo fmt --all -- --check

  clippy-check:
    name: Clippy check
    runs-on: ubuntu-latest
    container:
      image: ${{ inputs.builder_image }}
    env:
      JOB_CACHE_PREFIX: mangata-node-clippy-job-cache-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false

          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
            CACHE_FOUND=true
          fi

          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

      - name: Install sccache-cache only on non-release runs
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        uses: mozilla-actions/sccache-action@v0.0.5
      - name: Set Rust caching env vars only on non-release run
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        run: |
          echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
          echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
          echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV
      - name: Run clippy
        run: cargo clippy -p pallet-xyk

      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "./target"
            "/usr/local/cargo/bin/"
            "/usr/local/cargo/registry/index/"
            "/usr/local/cargo/registry/cache/"
            "/usr/local/cargo/git/db/"
          )

            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"

  unit-test:
    name: Unit tests
    runs-on: [compile-gke]
    container:
      image: ${{ inputs.builder_image }}
    env:
      JOB_CACHE_PREFIX: mangata-node-unit-tests-cache-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false

          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
            CACHE_FOUND=true
          fi

          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

      - name: Install sccache-cache only on non-release runs
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        uses: mozilla-actions/sccache-action@v0.0.5
      - name: Set Rust caching env vars only on non-release run
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        run: |
          echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
          echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
          echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV

      - name: Run unit tests
        run: cargo test -j2

      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "./target"
            "/usr/local/cargo/bin/"
            "/usr/local/cargo/registry/index/"
            "/usr/local/cargo/registry/cache/"
            "/usr/local/cargo/git/db/"
          )

            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"

      - name: Fix permissions on self-hosted runner
        if: always()
        run: chown -R 1100:1100 $GITHUB_WORKSPACE

  coverage-report:
    name: Coverage report
    runs-on: [compile-gke]
    container:
      image: ${{ inputs.builder_image }}
      options: --security-opt seccomp=unconfined
    env:
      JOB_CACHE_PREFIX: mangata-node-coverage-job-cache-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false

          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
            CACHE_FOUND=true
          fi

          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

      - name: Install sccache-cache only on non-release runs
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        uses: mozilla-actions/sccache-action@v0.0.5
      - name: Set Rust caching env vars only on non-release run
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        run: |
          echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
          echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
          echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV

      - name: Install cargo-tarpaulin
        run: cargo install cargo-tarpaulin@0.26.1 --locked --force
      - name: Generate coverage report with cargo-tarpaulin
        run: cargo tarpaulin --timeout 120 --workspace -e rollup-runtime-integration-test rollup-node rollup-runtime --exclude-files **/mock.rs **/weights.rs **/weights/* --out Xml
      - name: Upload to codecov.io
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.ORG_CODECOV_TOKEN }}
          fail_ci_if_error: false

      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "./target"
            "/usr/local/cargo/bin/"
            "/usr/local/cargo/registry/index/"
            "/usr/local/cargo/registry/cache/"
            "/usr/local/cargo/git/db/"
          )

            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"

      - name: Fix permissions on self-hosted runner
        if: always()
        run: chown -R 1100:1100 $GITHUB_WORKSPACE

  run-benchmarks-tests:
    name: Run benchmark tests
    runs-on: ubuntu-latest
    container:
      image: ${{ inputs.builder_image }}
    env:
      JOB_CACHE_PREFIX: mangata-node-becnhmark-tests-job-cache-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false

          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
            CACHE_FOUND=true
          fi

          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

      - name: Install sccache-cache only on non-release runs
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        uses: mozilla-actions/sccache-action@v0.0.5
      - name: Set Rust caching env vars only on non-release run
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        run: |
          echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
          echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
          echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV
      - name: Run benchmarks tests
        run: cargo test --release -j8 --features=runtime-benchmarks -p pallet-xyk -p pallet-issuance -p pallet-multipurpose-liquidity -p pallet-fee-lock
      - name: Run benchmarks tests
        run: cargo test --release -j8 --features=runtime-benchmarks -p pallet-bootstrap
      # NOTE: MGX-742
      - name: Run benchmarks tests
        run: cargo test --release -j8 --features=runtime-benchmarks -p pallet-proof-of-stake

      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "./target"
            "/usr/local/cargo/bin/"
            "/usr/local/cargo/registry/index/"
            "/usr/local/cargo/registry/cache/"
            "/usr/local/cargo/git/db/"
          )

            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"

  # build-and-run-try-runtime:
  #   name: Run try-runtime checks
  #   runs-on: [compile-gke]
  #   container:
  #     image: ${{ inputs.builder_image }}
  #   env:
  #     JOB_CACHE_PREFIX: mangata-node-try-runtime-job-cache-${{ inputs.cache-version }}
  #     CACHE_ARCHIVE_NAME: cache_archive.tar.zst
  #   steps:
  #     - uses: actions/checkout@v4
  #     - uses: google-github-actions/auth@v2
  #       id: auth
  #       with:
  #         workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
  #         service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
  #     - uses: google-github-actions/setup-gcloud@v2

  #     - name: Download cargo build cache
  #       if: inputs.cache-enabled
  #       id: cache
  #       run: |
  #         set -x
  #         CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
  #         ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
  #         CACHE_FOUND=false

  #         if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
  #           CACHE_FOUND=true
  #         fi

  #         echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
  #         echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

  #     - name: Install sccache-cache only on non-release runs
  #       if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
  #       uses: mozilla-actions/sccache-action@v0.0.5
  #     - name: Set Rust caching env vars only on non-release run
  #       if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
  #       run: |
  #         echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
  #         echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
  #         echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
  #         echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
  #         echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV

  #     - name: Build try-runtime Rococo & Kusama node
  #       run: cargo build --release --features=try-runtime

  #     - name: Run try-runtime Kusama Mainnet
  #       run: try-runtime --runtime=target/release/wbuild/rollup-runtime/rollup_runtime.wasm on-runtime-upgrade live --uri wss://rollup-rpc.mangata.online:443

  # - name: Upload cargo build cache
  #   if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
  #   shell: bash
  #   run: |
  #     set -x
  #     CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
  #     ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
  #     CACHE_PATHS=(
  #       "./target"
  #       "/usr/local/cargo/bin/"
  #       "/usr/local/cargo/registry/index/"
  #       "/usr/local/cargo/registry/cache/"
  #       "/usr/local/cargo/git/db/"
  #     )

  #           SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
  #           echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

  #           SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
  #           echo "Upload completed in $SECONDS seconds"

  #     - name: Fix permissions on self-hosted runner
  #       if: always()
  #       run: chown -R 1100:1100 $GITHUB_WORKSPACE

  run-benchmarks:
    name: Run runtime benchmarks
    # `performance` self-hosted runners have 8 cores and 16GB of RAM
    runs-on: [performance-gke]
    container:
      image: ${{ inputs.builder_image }}
    env:
      STEPS: 2
      REPEATS: 1
      JOB_CACHE_PREFIX: mangata-node-run-benchmarks-job-cache-${{ inputs.cache-version }}
      CACHE_ARCHIVE_NAME: cache_archive.tar.zst
    steps:
      - uses: actions/checkout@v4
      - uses: google-github-actions/auth@v2
        id: auth
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      - uses: google-github-actions/setup-gcloud@v2

      - name: Download cargo build cache
        if: inputs.cache-enabled
        id: cache
        run: |
          set -x
          CACHE_KEY="${{ env.JOB_CACHE_PREFIX }}-${{ hashFiles('**/Cargo.lock') }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_FOUND=false

          if gcloud storage cp "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME" - | zstd -d | tar -xf - -C / ; then
            CACHE_FOUND=true
          fi

          echo "cache_found=$CACHE_FOUND" >> $GITHUB_OUTPUT
          echo "cache_key=$CACHE_KEY" >> $GITHUB_OUTPUT

      - name: Install sccache-cache only on non-release runs
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        uses: mozilla-actions/sccache-action@v0.0.5
      - name: Set Rust caching env vars only on non-release run
        if: github.event_name != 'release' && github.event_name != 'workflow_dispatch'
        run: |
          echo "SCCACHE_GCS_BUCKET=mangata-node-ci-cache" >> $GITHUB_ENV
          echo "SCCACHE_GCS_RW_MODE=READ_WRITE" >> $GITHUB_ENV
          echo "SCCACHE_GCS_KEY_PREFIX=${{ env.JOB_CACHE_PREFIX }}" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "CARGO_INCREMENTAL=0" >> $GITHUB_ENV

      - name: Compile code
        run: cargo build --release --no-default-features --features=runtime-benchmarks

      - name: Set full benchmark params
        if: ${{ contains(github.event.pull_request.labels.*.name, 'full-benchmarks') }}
        run: |
          echo "STEPS=50" >> $GITHUB_ENV
          echo "REPEATS=20" >> $GITHUB_ENV

      - name: Run pallet benchmarks
        run: |
          mkdir ./benchmarks && target/release/rollup-node benchmark pallet \
          -l=info,runtime::collective=warn,xyk=warn \
          --chain rollup-local \
          --wasm-execution compiled \
          --pallet '*' \
          --extrinsic '*' \
          --steps ${{ env.STEPS }} \
          --repeat ${{ env.REPEATS }} \
          --template ./templates/module-weight-template.hbs \
          --output ./benchmarks/

      - name: Run block & extrinsic overhead benchmarks
        run: |
          target/release/rollup-node benchmark overhead --chain rollup-local -lblock_builder=debug --max-ext-per-block 50000 --base-path .
          cp block_weights.rs extrinsic_weights.rs ./benchmarks

      - name: Upload logs and docker images to GitHub
        if: ${{ contains(github.event.pull_request.labels.*.name, 'full-benchmarks') }}
        uses: actions/upload-artifact@v3.1.1
        with:
          name: benchmarks
          path: ./benchmarks

      - name: Upload cargo build cache
        if: inputs.cache-enabled && steps.cache.outputs.cache_found == 'false'
        shell: bash
        run: |
          set -x
          CACHE_KEY="${{ steps.cache.outputs.cache_key }}"
          ARCHIVE_NAME="${{ env.CACHE_ARCHIVE_NAME }}"
          CACHE_PATHS=(
            "./target"
            "/usr/local/cargo/bin/"
            "/usr/local/cargo/registry/index/"
            "/usr/local/cargo/registry/cache/"
            "/usr/local/cargo/git/db/"
          )

            SECONDS=0; tar -cf - "${CACHE_PATHS[@]}" | zstd -T0 -5 > "$ARCHIVE_NAME"
            echo "Compression completed in $SECONDS seconds" && echo "Archive size: $(du -h "$ARCHIVE_NAME" | cut -f1)"

            SECONDS=0; gcloud storage cp "$ARCHIVE_NAME" "gs://mangata-node-ci-cache/$CACHE_KEY/$ARCHIVE_NAME"
            echo "Upload completed in $SECONDS seconds"

      - name: Fix permissions on self-hosted runner
        if: always()
        run: chown -R 1100:1100 $GITHUB_WORKSPACE
